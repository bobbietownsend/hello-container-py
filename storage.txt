Question 1:You want to upload files from an on-premises virtual machine to Google Cloud Storage as part of a data migration. These files will be consumed by Cloud DataProc Hadoop cluster in a GCP environment. Which command should you use?gsutil cp [LOCAL_OBJECT] gs://[DESTINATION_BUCKET_NAME]/(Correct)gcloud cp [LOCAL_OBJECT] gs://[DESTINATION_BUCKET_NAME]/hadoop fs cp [LOCAL_OBJECT] gs://[DESTINATION_BUCKET_NAME]/gcloud dataproc cp [LOCAL_OBJECT] gs://[DESTINATION_BUCKET_NAME]/ExplanationTo upload files from an on-premises virtual machine to Google Cloud Storage as part of a data migration, you should use the command gsutil cp [LOCAL_OBJECT] gs://[DESTINATION_BUCKET_NAME]/.The gsutil cp command is used to copy files and objects between a local file system and a Cloud Storage bucket, or between Cloud Storage buckets. The gsutil cp command requires the path of the local file or object, and the destination Cloud Storage bucket.Here is an example of how you would use the gsutil cp command to upload a file called "example.txt" from the local file system to a Cloud Storage bucket called "example-bucket":gsutil cp example.txt gs://example-bucket/It's important to note that gsutil command-line tool must be installed on the on-premises virtual machine, this tool will help you to interact with GCP services.Additionally, you should also ensure that you have the appropriate permissions to upload files to the destination Cloud Storage bucket, and that the bucket is in the same project as the DataProc cluster to access the files.Question 14:Your service adds text to images that it reads from Cloud Storage. During busy times of the year, requests to Cloud Storage fail with an HTTP 429 "Too Many Requests" status code. How should you handle this error?Add a cache-control header to the objects.Request a quota increase from the GCP Console.Retry the request with a truncated exponential backoff strategy.(Correct)Change the storage class of the Cloud Storage bucket to Multi-regional.Explanationhttps://developers.google.com/gmail/api/v1/reference/quotaThis strategy would involve initially retrying the request immediately after receiving the "Too Many Requests" status code, then incrementally increasing the amount of time between retries with each subsequent failure. This allows for a balance between quickly retrying the request and not overwhelming the service with too many requests in a short period of time. Additionally, it's recommended to implement a maximum limit of retries, and to consider logging the errors and monitoring the retry rate to determine if additional steps are needed to optimize the application and avoid the 429 errors.Question 18:You plan to make a simple HTML application available on the internet. This site keeps information about FAQs for your application. The application is static and contains images, HTML, CSS, and Javascript. You want to make this application available on the internet with as few steps as possible. What should you do?Upload your application to Cloud Storage.(Correct)Upload your application to an App Engine environment.Create a Compute Engine instance with Apache web server installed. Configure Apache web server to host the application.Containerize your application first. Deploy this container to Google Kubernetes Engine (GKE) and assign an external IP address to the GKE pod hosting the application.Explanationhttps://cloud.google.com/storage/docs/hosting-static-websitev One option would be to use a cloud storage service such as Amazon S3, Google Cloud Storage, or Microsoft Azure Storage to host your static website. These services allow you to easily upload your HTML, CSS, Javascript, and image files, and then configure your bucket to be publicly accessible as a static website. Once your files are uploaded, you can then use the provided URL to access your website from anywhere on the internet.Question 188:Your company has created an application that uploads a report to a Cloud Storage bucket. When the report is uploaded to the bucket, you want to publish a message to a Cloud Pub/Sub topic. You want to implement a solution that will take a small amount to effort to implement. What should you do?Create an application deployed in a Google Kubernetes Engine cluster to receive the file; when it is received, publish a message to the Cloud Pub/Sub topic.Create an App Engine application to receive the file; when it is received, publish a message to the Cloud Pub/Sub topic.Configure the Cloud Storage bucket to trigger Cloud Pub/Sub notifications when objects are modified.(Correct)Create a Cloud Function that is triggered by the Cloud Storage bucket. In the Cloud Function, publish a message to the Cloud Pub/Sub topic.Question 7:Your organization has recently begun an initiative to replatform their legacy applications onto Google Kubernetes Engine. You need to decompose a monolithic application into microservices. Multiple instances have read and write access to a configuration file, which is stored on a shared file system. You want to minimize the effort required to manage this transition, and you want to avoid rewriting the application code. What should you do?Create a new Cloud Storage bucket, and mount it via FUSE in the container.Create a new ConfigMap and volumeMount to store the contents of the configuration file.Create a new Filestore instance, and mount the volume as an NFS PersistentVolume.(Correct)Create a new persistent disk, and mount the volume as a shared PersistentVolume.Explanationhttps://kubernetes.io/docs/concepts/storage/volumes/#nfs An nfs volume allows an existing NFS (Network File System) share to be mounted into a Pod. Unlike emptyDir, which is erased when a Pod is removed, the contents of an nfs volume are preserved and the volume is merely unmounted. This means that an NFS volume can be pre-populated with data, and that data can be shared between pods. NFS can be mounted by multiple writers simultaneously.Question 32:You are developing an application that will store and access sensitive unstructured data objects in a Cloud Storage bucket. To comply with regulatory requirements, you need to ensure that all data objects are available for at least 7 years after their initial creation. Objects created more than 3 years ago are accessed very infrequently (less than once a year). You need to configure object storage while ensuring that storage cost is optimized. What should you do? (Choose two.)Implement a Cloud Function that checks the age of each object in the bucket and moves the objects older than 3 years to a second bucket with the Archive Storage class. Use Cloud Scheduler to trigger the Cloud Function on a daily schedule.Use IAM Conditions to provide access to objects 7 years after the object creation date.Enable Object Versioning to prevent objects from being accidentally deleted for 7 years after object creation.Create an object lifecycle policy on the bucket that moves objects from Standard Storage to Archive Storage after 3 years.(Correct)Set a retention policy on the bucket with a period of 7 years.(Correct)Explanationhttps://cloud.google.com/storage/docs/bucket-lock This page discusses the Bucket Lock feature, which allows you to configure a data retention policy for a Cloud Storage bucket that governs how long objects in the bucket must be retained. The feature also allows you to lock the data retention policy, permanently preventing the policy from being reduced or removed. https://cloud.google.com/storage/docs/storage-classes#archive Archive storage is the lowest-cost, highly durable storage service for data archiving, online backup, and disaster recovery. Unlike the "coldest" storage services offered by other Cloud providers, your data is available within milliseconds, not hours or days. Archive storage is the best choice for data that you plan to access less than once a year.Question 35:You are building a highly available and globally accessible application that will serve static content to users. You need to configure the storage and serving components. You want to minimize management overhead and latency while maximizing reliability for users. What should you do?1. Create a Standard storage class, regional Cloud Storage bucket. Put the static content in the bucket2. Reserve an external IP address, and create an external HTTP(S) load balancer3. Enable Cloud CDN, and send traffic to your backend bucket1. Create a Standard storage class, multi-regional Cloud Storage bucket. Put the static content in the bucket.2. Reserve an external IP address, and create an external HTTP(S) load balancer.3. Enable Cloud CDN, and send traffic to your backend bucket.(Correct)1. Create a managed instance group. Replicate the static content across the virtual machines (VMs)2. Create an external HTTP(S) load balancer.3. Enable Cloud CDN, and send traffic to the managed instance group.1. Create an unmanaged instance group. Replicate the static content across the VMs.2. Create an external HTTP(S) load balancer3. Enable Cloud CDN, and send traffic to the unmanaged instance group.Question 40:Your company has created an application that uploads a report to a Cloud Storage bucket. When the report is uploaded to the bucket, you want to publish a message to a Cloud Pub/Sub topic. You want to implement a solution that will take a small amount to effort to implement. What should you do?Create an application deployed in a Google Kubernetes Engine cluster to receive the file; when it is received, publish a message to the Cloud Pub/Sub topic.Create an App Engine application to receive the file; when it is received, publish a message to the Cloud Pub/Sub topic.Configure the Cloud Storage bucket to trigger Cloud Pub/Sub notifications when objects are modified.(Correct)Create a Cloud Function that is triggered by the Cloud Storage bucket. In the Cloud Function, publish a message to the Cloud Pub/Sub topic.Question 20:You are developing an application that needs to store files belonging to users in Cloud Storage. You want each user to have their own subdirectory in Cloud Storage. When a new user is created, the corresponding empty subdirectory should also be created. What should you do?Create an object with the name of the subdirectory, and then immediately delete the object within that subdirectory.Create an object with the name of the subdirectory ending with a trailing slash ('/') that is zero bytes in length.(Correct)Create an object with the name of the subdirectory that is zero bytes in length and has WRITER access control list permission.Create an object with the name of the subdirectory that is zero bytes in length. Set the Content-Type metadata to CLOUDSTORAGE_FOLDER.Explanationhttps://cloud.google.com/storage/docs/folders If you create an empty folder using the Google Cloud console, Cloud Storage creates a zero-byte object as a placeholder. For example, if you create a folder called folder in a bucket called my-bucket, a zero- byte object called gs://my-bucket/folder/ is created. This placeholder is discoverable by other tools when listing the objects in the bucket, for example when using the gsutil ls command.